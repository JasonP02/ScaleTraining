## Transformer architecture knobs

n_layer: 24
max_seq_len: 2048
n_head: 14
n_embed: 896
n_hidden: 4864
bias: true
UE_bias: false
activation: relu
attn_dropout: 0.2
resid_dropout: 0.2
use_checkpoint: false
use_rope: true
rope_config:
  theta: 1000000.0
  use_complex: true
