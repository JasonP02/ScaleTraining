Working on:
Loss vs flops

Next task:
perplexity vs context length.

Questions:
- How do batching approaches affect model convergence / learning efficency & training speed 

